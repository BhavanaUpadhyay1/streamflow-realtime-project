# streamflow-realtime-project

# âš¡ Real-Time E-Commerce Data Engineering Project
End-to-end real-time data pipeline built with **Kafka, Spark Structured Streaming, Delta Lake, and Snowflake**, powering analytics dashboards in **Power BI/Tableau**.

---

## ğŸ“– Description
This project simulates a real-time e-commerce system.  
It ingests **live order/customer events** into Kafka, processes them with **PySpark Streaming**, stores data in **Delta Lake/Snowflake** (Bronze â†’ Silver â†’ Gold layers), and visualizes insights in **BI dashboards**.  

Designed to demonstrate **scalable streaming data engineering architecture**.

---

## âœ¨ Features
- âš¡ **Real-time ingestion** using Kafka Producers  
- ğŸ”„ **Stream processing** with Spark Structured Streaming  
- ğŸ›¢ï¸ **Delta Lake & Snowflake storage** (Bronze â†’ Silver â†’ Gold)  
- ğŸ“Š **Analytics dashboards** with Power BI / Tableau  
- ğŸ—ï¸ **Star & Snowflake schemas** for reporting  
- ğŸ”’ **Checkpointing & fault tolerance** in Spark  

---

## ğŸ“‚ Folder Structure


realtime-project/


â”œâ”€â”€ producer/ # Kafka Producers (simulate events)
â”‚ â””â”€â”€ order_producer.py
â”‚
â”œâ”€â”€ consumer/ # Spark Streaming jobs
â”‚ â”œâ”€â”€ order_consumer.py
â”‚ â””â”€â”€ checkpoint/ # Spark checkpoints
â”‚
â”œâ”€â”€ storage/ # Storage scripts
â”‚ â”œâ”€â”€ delta/ # Delta Lake scripts
â”‚ â””â”€â”€ snowflake/ # Snowflake integration
â”‚
â”œâ”€â”€ config/ # Configuration files
â”‚ â”œâ”€â”€ kafka_config.json
â”‚ â””â”€â”€ spark_config.json
â”‚
â”œâ”€â”€ dashboard/ # Dashboards
â”‚ â”œâ”€â”€ powerbi_dashboard.pbix
â”‚ â””â”€â”€ tableau_dashboard.twb
â”‚
â”œâ”€â”€ docs/ # Documentation
â”‚ â”œâ”€â”€ architecture.png
â”‚ â””â”€â”€ data_model.md
â”‚
â”œâ”€â”€ tests/ # Unit tests
â”‚
â”œâ”€â”€ requirements.txt # Python dependencies
â””â”€â”€ README.md # Project documentation

## ğŸ› ï¸ Installation
```bash
# 1ï¸âƒ£ Clone the repository
git clone https://github.com/<BhavanaUpadhyay1>/streamflow-realtime-project.git

# 2ï¸âƒ£ Navigate into the folder
cd streamflow-realtime-project

# 3ï¸âƒ£ Create & activate virtual environment
python -m venv realtime_env
realtime_env\Scripts\activate   # (Windows)
source realtime_env/bin/activate # (Mac/Linux)

# 4ï¸âƒ£ Install dependencies
pip install -r requirements.txt

## ğŸš€ Usage

### 1ï¸âƒ£ Start Kafka Services (Windows Example)
```bash
# Start Zookeeper
.\bin\windows\zookeeper-server-start.bat .\config\zookeeper.properties

# Start Kafka broker
.\bin\windows\kafka-server-start.bat .\config\server.properties

# Create Kafka topic
.\bin\windows\kafka-topics.bat --create --topic orders --bootstrap-server localhost:9092 --partitions 3 --replication-factor 1

2ï¸âƒ£ Run Producer (simulate order events)
python producer/order_producer.py

3ï¸âƒ£ Run Spark Consumer (process events from Kafka)
spark-submit consumer/order_consumer.py

ğŸ“Š Analytics

Bronze Layer â†’ Raw Kafka events

Silver Layer â†’ Cleaned & structured data

Gold Layer â†’ Facts & Dimensions for BI

Connect Power BI/Tableau to Snowflake/Delta Lake and build KPIs like:

Sales by region

Active customers

Top products

ğŸ¤ Contributing

Fork the repo

Create a new branch: git checkout -b feature-name

Commit changes: git commit -m "Add feature"

Push: git push origin feature-name

Open Pull Request

ğŸ“œ License

This project is licensed under the MIT License â€” see LICENSE
 for details.

ğŸ“§ Contact

Author: Bhavana Upadhyay
GitHub: BhavanaUpadhyay1

Email: bhavanaupadhyay360@gmail.com

